{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-20T20:35:09.272138Z",
     "start_time": "2024-08-20T20:35:04.516184Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import guidance\n",
    "from textwrap import dedent\n",
    "import json \n",
    "\n",
    "from grammar_guide import guide, load_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_name_or_path = \"HuggingFaceTB/SmolLM-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "parser = load_parser(lark_grammar_filepath=\"../grammars/json.lark\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T20:35:10.157930Z",
     "start_time": "2024-08-20T20:35:09.273355Z"
    }
   },
   "id": "3f8de4fda975943c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8636739253997803\n",
      "11.388124580271679\n",
      "{\"name\": \"Joseph Smith, 32\", \"age\": 32, \"job\": \"K\" , \"location\": \"Apple\", \"city\": \"San Francisco\", \"state\": \"CA\"}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\",\n",
    "    max_new_tokens=20,\n",
    "    return_full_text=True\n",
    ")\n",
    "prompt = dedent(\"\"\"\n",
    "Here is a really long, nested JSON that extracts fields from this sentence:\\n\\nMy name is Joseph Smith, and I work at Apple. I'm 32 years old, and my interests include kayaking, skiing, snowboarding, and woodworking.\\n\\n```json\\n\n",
    "\"\"\")\n",
    "res = guide(\n",
    "    model=lambda x: pipe(x)[0]['generated_text'].lstrip(prompt),\n",
    "    parser=parser,\n",
    "    seed_str=\"\"\"{\"name\":\"\"\",\n",
    "    prompt=prompt,\n",
    "    draft_model=guidance.models.Transformers(\n",
    "        model_name_or_path, echo=False\n",
    "    ),\n",
    "    max_grammar_corrections=20,\n",
    "    verbose=False,\n",
    ")\n",
    "print(res.process_time_seconds)\n",
    "print(len(tokenizer(res.response)['input_ids']) / res.process_time_seconds)\n",
    "print(res.response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T20:36:15.294855Z",
     "start_time": "2024-08-20T20:36:10.973167Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.000513792037964\n",
      "20.747335046111086\n"
     ]
    }
   ],
   "source": [
    "res = guide(\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    parser=parser,\n",
    "    seed_str=\"\"\"{\"name\":\"\"\",\n",
    "    prompt=dedent(\"\"\"\n",
    "    Here is a really long, nested JSO that extracts fields from this sentence:\\n\\nMy name is Joseph Smith, and I work at Apple. I'm 32 years old, and my interests include kayaking, skiing, snowboarding, and woodworking.\\n\\n```json\\n\n",
    "    \"\"\"),\n",
    "    draft_model=guidance.models.Transformers(\n",
    "        model_name_or_path, echo=False\n",
    "    ),\n",
    "    stop_at=['```'],\n",
    "    max_grammar_corrections=20,\n",
    "    verbose=False,\n",
    "    max_new_tokens=20,\n",
    "    temperature=0.0,\n",
    ")\n",
    "print(res.process_time_seconds)\n",
    "print(len(tokenizer(res.response)['input_ids']) / res.process_time_seconds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T20:35:24.996156Z",
     "start_time": "2024-08-20T20:35:20.519544Z"
    }
   },
   "id": "56d2f6feb26acfbe"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"Joseph Smith, 32 years old, and my interests include kayaking, skiing, snow\",\n",
      "    \"age\": 32,\n",
      "    \"occupation\": \"skiing, skiing, snowboarding, and woodworking\",\n",
      "    \"job\": \"johnson\",\n",
      "    \"job_title\": \"johnson\",\n",
      "    \"job_description\": \"johnson\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(json.dumps(json.loads(res.response), indent = 4))\n",
    "except:\n",
    "    print(res.response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T20:32:23.428024Z",
     "start_time": "2024-08-20T20:32:23.402816Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "blendsql",
   "language": "python",
   "display_name": "blendsql"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
