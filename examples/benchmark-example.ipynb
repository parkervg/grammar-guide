{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-29T12:01:48.101052Z",
     "start_time": "2024-08-29T12:01:45.274704Z"
    }
   },
   "outputs": [],
   "source": [
    "from string import Template\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import guidance\n",
    "from textwrap import dedent\n",
    "import grammar_guide as gg\n",
    "from transformers import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "STOP_STRING_LIST = [\"```\", \"}\"]\n",
    "\n",
    "def load_model(model_name_or_path: str):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name_or_path, device_map=\"cuda\" if torch.cuda.is_available() else None\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "    return (model, tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T12:01:48.107062Z",
     "start_time": "2024-08-29T12:01:48.101617Z"
    }
   },
   "id": "80353a9f06a13ab1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "num_json_keys = 10\n",
    "\n",
    "prompt = dedent(\n",
    "    f\"\"\"\n",
    "        This is an introduction to a prompt. It is intended to mimick the lengthy few-shot prompts we tend to use.\n",
    "        Anyways, now I will get to my real point.\n",
    "        Here is a JSON object, with {num_json_keys} keys, using only string values:\\n\\n```json\\n\n",
    "        \"\"\"\n",
    ")\n",
    "lark_grammar_str = Template(\n",
    "    open(\"./benchmarks/json.lark\").read()\n",
    ")\n",
    "lark_grammar_str = lark_grammar_str.safe_substitute(\n",
    "    NUM_REPEATS=f\"{num_json_keys - 1}\"\n",
    ")\n",
    "\n",
    "model_name_or_path = \"HuggingFaceTB/SmolLM-135M\"\n",
    "model, tokenizer = load_model(model_name_or_path=model_name_or_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T12:01:48.992504Z",
     "start_time": "2024-08-29T12:01:48.109658Z"
    }
   },
   "id": "3c9e217aa1e5b864"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass:\n",
      "\n",
      "        This is an introduction to a prompt. It is intended to mimick the lengthy few-shot prompts we tend to use.\n",
      "        Anyways, now I will get to my real point.\n",
      "        Here is a JSON object, with 10 keys, using only string values:\n",
      "\n",
      "```json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mMade a single_candidate correction...\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous kv cache size: 78\n",
      "New size: 75\n",
      "Previous kv cache size: 75\n",
      "New size: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mMade a single_candidate correction...\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous kv cache size: 92\n",
      "New size: 82\n",
      "Forward pass:\n",
      " \n",
      "Previous kv cache size: 83\n",
      "New size: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mMade a single_candidate correction...\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous kv cache size: 100\n",
      "New size: 99\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m set_seed(\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mgg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mguide\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlark_grammar_str\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdraft_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mguidance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTransformers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mecho\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstop_at\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mSTOP_STRING_LIST\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_grammar_corrections\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_healing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdebug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/projects/grammar-guide/grammar_guide/guide.py:48\u001B[0m, in \u001B[0;36mguide\u001B[0;34m(model, parser, prompt, draft_model, tokenizer, seed_str, max_grammar_corrections, stop_at, token_healing, top_p, temperature, max_new_tokens, save_html, verbose, debug)\u001B[0m\n\u001B[1;32m     46\u001B[0m     logger\u001B[38;5;241m.\u001B[39msetLevel(logging\u001B[38;5;241m.\u001B[39mERROR)\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfig\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m---> 48\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_transformers_guide\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdraft_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdraft_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseed_str\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed_str\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_grammar_corrections\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_grammar_corrections\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstop_at\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop_at\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken_healing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_healing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     60\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_new_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m        \u001B[49m\u001B[43msave_html\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_html\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdebug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdebug\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model, Callable)\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _generic_guide(\n\u001B[1;32m     67\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     68\u001B[0m     parser\u001B[38;5;241m=\u001B[39mparser,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     72\u001B[0m     max_grammar_corrections\u001B[38;5;241m=\u001B[39mmax_grammar_corrections,\n\u001B[1;32m     73\u001B[0m )\n",
      "File \u001B[0;32m~/Desktop/projects/grammar-guide/grammar_guide/guide.py:263\u001B[0m, in \u001B[0;36m_transformers_guide\u001B[0;34m(model, tokenizer, parser, prompt, draft_model, seed_str, max_grammar_corrections, stop_at, token_healing, top_p, temperature, max_new_tokens, save_html, verbose, debug)\u001B[0m\n\u001B[1;32m    261\u001B[0m         rstrip_s \u001B[38;5;241m=\u001B[39m rstrip_s[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    262\u001B[0m     stripped_prefix \u001B[38;5;241m=\u001B[39m stripped_prefix\u001B[38;5;241m.\u001B[39mrstrip(rstrip_s)\n\u001B[0;32m--> 263\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m stripped_pred \u001B[38;5;241m==\u001B[39m stripped_prefix\n\u001B[1;32m    264\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stripped_pred \u001B[38;5;241m==\u001B[39m stripped_prefix:\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "res = gg.guide(\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    parser=gg.load_parser(lark_grammar_str),\n",
    "    prompt=prompt,\n",
    "    draft_model=guidance.models.Transformers(model_name_or_path, echo=False),\n",
    "    stop_at=STOP_STRING_LIST,\n",
    "    max_grammar_corrections=10,\n",
    "    max_new_tokens=15,\n",
    "    temperature=0.0,\n",
    "    token_healing=True,\n",
    "    verbose=True,\n",
    "    debug=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T12:01:53.865420Z",
     "start_time": "2024-08-29T12:01:48.993729Z"
    }
   },
   "id": "f32d3677b9461ac"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass:\n",
      "\n",
      "        This is an introduction to a prompt. It is intended to mimick the lengthy few-shot prompts we tend to use.\n",
      "        Anyways, now I will get to my real point.\n",
      "        Here is a JSON object, with 10 keys, using only string values:\n",
      "\n",
      "```json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mMade a single_candidate correction...\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous kv cache size: 78\n",
      "New size: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mMade a draft_gen correction...\u001B[39m\n",
      "\u001B[33mMade a single_candidate correction...\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous kv cache size: 107\n",
      "New size: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mMade a single_candidate correction...\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous kv cache size: 102\n",
      "New size: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mMade a single_candidate correction...\u001B[39m\n",
      "\u001B[33mMade a single_candidate correction...\u001B[39m\n",
      "\u001B[33mMade a single_candidate correction...\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous kv cache size: 103\n",
      "New size: 100\n",
      "Previous kv cache size: 103\n",
      "New size: 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mMade a single_candidate correction...\u001B[39m\n",
      "\u001B[33mMade a single_candidate correction...\u001B[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous kv cache size: 121\n",
      "New size: 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mMade a single_candidate correction...\u001B[39m\n",
      "\u001B[31mCannot find a valid prediction after 10 retries\u001B[39m\n"
     ]
    },
    {
     "data": {
      "text/html": "<div style='margin: 0px; padding: 0px; font-family: ColfaxAI, Arial; font-size: 20px;'<text style=color:black>\n       </text><text style=color:black> This</text><text style=color:black> is</text><text style=color:black> an</text><text style=color:black> introduction</text><text style=color:black> to</text><text style=color:black> a</text><text style=color:black> prompt</text><text style=color:black>.</text><text style=color:black> It</text><text style=color:black> is</text><text style=color:black> intended</text><text style=color:black> to</text><text style=color:black> mim</text><text style=color:black>ick</text><text style=color:black> the</text><text style=color:black> lengthy</text><text style=color:black> few</text><text style=color:black>-</text><text style=color:black>shot</text><text style=color:black> prompts</text><text style=color:black> we</text><text style=color:black> tend</text><text style=color:black> to</text><text style=color:black> use</text><text style=color:black>.</text><text style=color:black>\n       </text><text style=color:black> Any</text><text style=color:black>ways</text><text style=color:black>,</text><text style=color:black> now</text><text style=color:black> I</text><text style=color:black> will</text><text style=color:black> get</text><text style=color:black> to</text><text style=color:black> my</text><text style=color:black> real</text><text style=color:black> point</text><text style=color:black>.</text><text style=color:black>\n       </text><text style=color:black> Here</text><text style=color:black> is</text><text style=color:black> a</text><text style=color:black> JSON</text><text style=color:black> object</text><text style=color:black>,</text><text style=color:black> with</text><text style=color:black> </text><text style=color:black>1</text><text style=color:black>0</text><text style=color:black> keys</text><text style=color:black>,</text><text style=color:black> using</text><text style=color:black> only</text><text style=color:black> string</text><text style=color:black> values</text><text style=color:black>:</text><text style=color:black>\n</text><text style=color:black>\n</text><text style=color:black>```</text><text style=color:black>json</text><text style=color:black>\n\n</text><text style=color:black>{</text><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\n   </text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black> \"</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>name</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\":</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black> \"</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>John</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\",</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\n   </text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black> \"</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>age</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\":</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black> </text></span><text style=color:red>3</text><text style=color:red>5</text><text style=color:red>,</text><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:red>\n   </text></span><span style='background-color: rgba(0, 0, 165, 0.25);'><text style=color:blue>\"</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>2</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>5</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\",</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\n   </text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black> \"</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>city</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\":</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black> \"</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>New</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black> York</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\",</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\n   </text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black> \"</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>state</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\":</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black> \"</text></span><span style='background-color: rgba(0, 0, 165, 0.25);'><text style=color:blue>NY</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>,</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\n   </text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black> \"</text></span><text style=color:red>country</text><text style=color:red>\":</text><text style=color:red> \"</text><text style=color:red>USA</text><text style=color:red>\",</text><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:red>\n   </text></span><text style=color:red> \"</text><text style=color:red>address</text><text style=color:red>\":</text><text style=color:red> \"</text><text style=color:red>1</text><text style=color:red>2</text><text style=color:red>3</text><span style='background-color: rgba(0, 0, 165, 0.25);'><text style=color:blue>,</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\":</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black> \"</text></span><text style=color:red>USA</text><text style=color:red>\"</text><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:red>\n</text></span><text style=color:red>}</text><span style='background-color: rgba(0, 0, 165, 0.25);'><text style=color:blue>:</text></span><text style=color:red>US</text><text style=color:red>\"</text><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:red>\n</text></span><text style=color:red>}</text><span style='background-color: rgba(0, 0, 165, 0.25);'><text style=color:blue>\"</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\n</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>}</text></span><span style='background-color: rgba(0, 0, 165, 0.25);'><text style=color:blue>\"</text></span><text style=color:red>}</text><span style='background-color: rgba(0, 0, 165, 0.25);'><text style=color:blue>,</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\n</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\"</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>phone</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\":</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black> \"</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>1</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>2</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>3</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>4</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>5</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>6</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>7</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>8</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>9</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>0</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>1</text></span><span style='background-color: rgba(0, 0, 165, 0.25);'><text style=color:blue>\"</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\n</text></span><text style=color:red>}</text><span style='background-color: rgba(0, 0, 165, 0.25);'><text style=color:blue>,</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\n</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\"</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>email</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\":</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black> \"<</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>EMAIL</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>>\"</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\n</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>,</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\n</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\"</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>address</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>\":</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black> \"</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>1</text></span><span style='background-color: rgba(0, 165, 0, 0.25);'><text style=color:black>2</text></span><span style='background-color: rgba(0, 0, 165, 0.25);'><text style=color:blue>\"</text></span></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "res = gg.guide(\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    parser=gg.load_parser(lark_grammar_str),\n",
    "    prompt=prompt,\n",
    "    draft_model=guidance.models.Transformers(model_name_or_path, echo=False),\n",
    "    stop_at=STOP_STRING_LIST,\n",
    "    max_grammar_corrections=10,\n",
    "    max_new_tokens=15,\n",
    "    temperature=0.0,\n",
    "    token_healing=False,\n",
    "    verbose=True,\n",
    "    debug=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T12:00:29.692064Z",
     "start_time": "2024-08-29T12:00:23.674198Z"
    }
   },
   "id": "ea07c1279d752398"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"name\": \"John\",\n",
      " \"age\": \"20\",\n",
      " \"city\": \"New York\",\n",
      " \"email\": \"<\",\"\n",
      " \":\"\n",
      " \",\":\n",
      " \":\"\n",
      " \"\n"
     ]
    }
   ],
   "source": [
    "print(res.response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T11:44:15.123384Z",
     "start_time": "2024-08-29T11:44:15.107410Z"
    }
   },
   "id": "6f17e4d7e6eed69f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "467b377668522d39"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
